{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from PIL import ImageEnhance\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.keras.models import Model\n",
    "from tensorflow.python.keras.layers import Input, Conv2D, MaxPooling2D, Dropout, concatenate, Conv2DTranspose\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_image(image, patch_size):\n",
    "    width, height = image.size\n",
    "    patches = []\n",
    "    \n",
    "    for y in range(0, height, patch_size):\n",
    "        for x in range(0, width, patch_size):\n",
    "            if(x+patch_size<=1024 and y+patch_size<=1024):\n",
    "                patch = image.crop((x, y, x+patch_size, y+patch_size))\n",
    "                patches.append(patch)\n",
    "            elif(x+patch_size>1024 and y+patch_size<=1024):\n",
    "                patch = image.crop((x-96, y, x+patch_size-96, y+patch_size))\n",
    "                patches.append(patch)\n",
    "            elif(x+patch_size<=1024 and y+patch_size>1024):\n",
    "                patch = image.crop((x, y-96, x+patch_size, y+patch_size-96))\n",
    "                patches.append(patch)\n",
    "            else:\n",
    "                patch = image.crop((x-96, y-96, x+patch_size-96, y+patch_size-96))\n",
    "                patches.append(patch)\n",
    "    \n",
    "    return patches\n",
    "\n",
    "def save_patches_image(patches, output_folder):\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    # 기존 이미지 파일들을 읽어옵니다.\n",
    "    existing_images = os.listdir(output_folder)\n",
    "\n",
    "    # 이미지 파일 이름을 숫자로 변환하여 정렬합니다.\n",
    "    existing_indices = [int(name.split('_')[1].split('.')[0]) for name in existing_images]\n",
    "    existing_indices.sort()\n",
    "\n",
    "    # 이미지를 저장합니다.\n",
    "    for i, patch in enumerate(patches):\n",
    "        # 기존 이미지들의 인덱스와 겹치지 않도록 새로운 인덱스를 설정합니다.\n",
    "        new_index = max(existing_indices) + i + 1 if existing_indices else i\n",
    "        patch.save(os.path.join(output_folder, f\"TRAIN_{new_index:04d}.png\"))\n",
    "\n",
    "def save_patches_mask(patches, output_folder):\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    # 기존 이미지 파일들을 읽어옵니다.\n",
    "    existing_images = os.listdir(output_folder)\n",
    "\n",
    "    # 이미지 파일 이름을 숫자로 변환하여 정렬합니다.\n",
    "    existing_indices = [int(name.split('_')[1].split('.')[0]) for name in existing_images]\n",
    "    existing_indices.sort()\n",
    "\n",
    "    # 이미지를 저장합니다.\n",
    "    for i, patch in enumerate(patches):\n",
    "        # 기존 이미지들의 인덱스와 겹치지 않도록 새로운 인덱스를 설정합니다.\n",
    "        new_index = max(existing_indices) + i + 1 if existing_indices else i\n",
    "        patch.save(os.path.join(output_folder, f\"mask_{new_index:04d}.png\"))\n",
    "\n",
    "    # 이미지를 저장합니다.\n",
    "    for i, patch in enumerate(patches):\n",
    "        # 기존 이미지들의 인덱스와 겹치지 않도록 새로운 인덱스를 설정합니다.\n",
    "        new_index = max(existing_indices) + i + 1 if existing_indices else i\n",
    "        patch.save(os.path.join(output_folder, f\"TRAIN_{new_index:04d}.png\"))\n",
    "\n",
    "# def save_patches_mask(patches, output_folder):\n",
    "#     if not os.path.exists(output_folder):\n",
    "#         os.makedirs(output_folder)\n",
    "    \n",
    "#     for i, patch in enumerate(patches):\n",
    "#         patch.save(os.path.join(output_folder, f\"mask_{i:04d}.png\"))\n",
    "\n",
    "# 1024x1024 이미지 로드\n",
    "for i in range(7140):\n",
    "    image = Image.open(f\"C:\\\\Users\\\\IT\\\\Desktop\\\\open\\\\train_img_1\\\\TRAIN_{i:04d}.png\")\n",
    "    mask = Image.open(f\"C:\\\\Users\\\\IT\\\\Desktop\\\\open\\\\mask_train_1\\\\mask_image_{i}.png\")\n",
    "\n",
    "    # 이미지를 224x224 크기의 패치로 잘라서 리스트에 저장\n",
    "    patch_size = 224\n",
    "    patches_img = crop_image(image, patch_size)\n",
    "    patches_mask = crop_image(mask, patch_size)\n",
    "\n",
    "    # 패치 이미지를 폴더에 저장\n",
    "    image_folder = \"C:\\\\Users\\\\IT\\\\Desktop\\\\open\\\\train_img\"\n",
    "    mask_folder = \"C:\\\\Users\\\\IT\\\\Desktop\\\\open\\\\mask_train\"\n",
    "    save_patches_image(patches_img, image_folder)\n",
    "    save_patches_mask(patches_mask, mask_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 밝기 바꿔서 저장\n",
    "def save_patches_image_add(patches, output_folder):\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    # 기존 이미지 파일들을 읽어옵니다.\n",
    "    existing_images = os.listdir(output_folder)\n",
    "\n",
    "    # 이미지 파일 이름을 숫자로 변환하여 정렬합니다.\n",
    "    existing_indices = [int(name.split('_')[1].split('.')[0]) for name in existing_images]\n",
    "    existing_indices.sort()\n",
    "\n",
    "    # 이미지를 저장합니다.\n",
    "    for i, patch in enumerate(patches):\n",
    "        # 기존 이미지들의 인덱스와 겹치지 않도록 새로운 인덱스를 설정합니다.\n",
    "        new_index = max(existing_indices) + i + 1 if existing_indices else i\n",
    "        patch.save(os.path.join(output_folder, f\"TRAIN_{new_index:04d}.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for i in range(7140):\n",
    "    patches = []\n",
    "    for j in range(25):\n",
    "        j += count\n",
    "        image = Image.open(f\"C:\\\\Users\\\\IT\\\\Desktop\\\\open\\\\train_img\\\\TRAIN_{j:04d}.png\")\n",
    "        # 밝기 조절\n",
    "        enhancer = ImageEnhance.Brightness(image)\n",
    "        brightened_image = enhancer.enhance(1.6)\n",
    "        patches.append(brightened_image)\n",
    "    count += 25\n",
    "\n",
    "    # 패치 이미지를 폴더에 저장\n",
    "    image_folder = \"C:\\\\Users\\\\IT\\\\Desktop\\\\open\\\\train_img_add2\"\n",
    "    save_patches_image_add(patches, image_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<PIL.Image.Image image mode=RGB size=224x224 at 0x1CD4E7C5B88>, <PIL.Image.Image image mode=RGB size=224x224 at 0x1CD4D8F3108>, <PIL.Image.Image image mode=RGB size=224x224 at 0x1CD4E7AF508>, <PIL.Image.Image image mode=RGB size=224x224 at 0x1CD4E7CBB08>, <PIL.Image.Image image mode=RGB size=224x224 at 0x1CD4E7CB2C8>, <PIL.Image.Image image mode=RGB size=224x224 at 0x1CD4D6945C8>, <PIL.Image.Image image mode=RGB size=224x224 at 0x1CD4E7CB988>, <PIL.Image.Image image mode=RGB size=224x224 at 0x1CD4E7B7448>, <PIL.Image.Image image mode=RGB size=224x224 at 0x1CD4E7B7B08>, <PIL.Image.Image image mode=RGB size=224x224 at 0x1CD4E7CB848>, <PIL.Image.Image image mode=RGB size=224x224 at 0x1CD4E7B78C8>, <PIL.Image.Image image mode=RGB size=224x224 at 0x1CD4E7B7908>, <PIL.Image.Image image mode=RGB size=224x224 at 0x1CD4E7B7C88>, <PIL.Image.Image image mode=RGB size=224x224 at 0x1CD4E7B7348>, <PIL.Image.Image image mode=RGB size=224x224 at 0x1CD4E7B7A88>, <PIL.Image.Image image mode=RGB size=224x224 at 0x1CD4E7B72C8>, <PIL.Image.Image image mode=RGB size=224x224 at 0x1CD4E7B7748>, <PIL.Image.Image image mode=RGB size=224x224 at 0x1CD4E7B7D08>, <PIL.Image.Image image mode=RGB size=224x224 at 0x1CD4E7B7F88>, <PIL.Image.Image image mode=RGB size=224x224 at 0x1CD4E7B7508>, <PIL.Image.Image image mode=RGB size=224x224 at 0x1CD4E7B7848>, <PIL.Image.Image image mode=RGB size=224x224 at 0x1CD4E7B77C8>, <PIL.Image.Image image mode=RGB size=224x224 at 0x1CD4E7B73C8>, <PIL.Image.Image image mode=RGB size=224x224 at 0x1CD6635F9C8>, <PIL.Image.Image image mode=RGB size=224x224 at 0x1CD66315588>]\n",
      "[<PIL.Image.Image image mode=L size=224x224 at 0x1CD4E7C8408>, <PIL.Image.Image image mode=L size=224x224 at 0x1CD4E7C5408>, <PIL.Image.Image image mode=L size=224x224 at 0x1CD4D8EC848>, <PIL.Image.Image image mode=L size=224x224 at 0x1CD4E7C5848>, <PIL.Image.Image image mode=L size=224x224 at 0x1CD4E7CDC48>, <PIL.Image.Image image mode=L size=224x224 at 0x1CD4E7CDDC8>, <PIL.Image.Image image mode=L size=224x224 at 0x1CD4E7CDBC8>, <PIL.Image.Image image mode=L size=224x224 at 0x1CD4E7CDC08>, <PIL.Image.Image image mode=L size=224x224 at 0x1CD4E7CD508>, <PIL.Image.Image image mode=L size=224x224 at 0x1CD4E7CDF08>, <PIL.Image.Image image mode=L size=224x224 at 0x1CD4E7CDD48>, <PIL.Image.Image image mode=L size=224x224 at 0x1CD4E7CDE48>, <PIL.Image.Image image mode=L size=224x224 at 0x1CD4E7CDEC8>, <PIL.Image.Image image mode=L size=224x224 at 0x1CD4E7AF208>, <PIL.Image.Image image mode=L size=224x224 at 0x1CD4E7AFF88>, <PIL.Image.Image image mode=L size=224x224 at 0x1CD4E7AFC88>, <PIL.Image.Image image mode=L size=224x224 at 0x1CD4E7AFE88>, <PIL.Image.Image image mode=L size=224x224 at 0x1CD4E7AFB48>, <PIL.Image.Image image mode=L size=224x224 at 0x1CD4E7AFA88>, <PIL.Image.Image image mode=L size=224x224 at 0x1CD6630D088>, <PIL.Image.Image image mode=L size=224x224 at 0x1CD4D69DD48>, <PIL.Image.Image image mode=L size=224x224 at 0x1CD6634ECC8>, <PIL.Image.Image image mode=L size=224x224 at 0x1CD4E7AFAC8>, <PIL.Image.Image image mode=L size=224x224 at 0x1CD4E7AF948>, <PIL.Image.Image image mode=L size=224x224 at 0x1CD4D6B1548>]\n"
     ]
    }
   ],
   "source": [
    "print(patches_img)\n",
    "print(patches_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# U-Net 모델 정의\n",
    "def unet(input_shape):\n",
    "    # 인코더 부분\n",
    "    inputs = Input(input_shape)\n",
    "\n",
    "    conv1 = Conv2D(16, 3, activation='relu', padding='same')(inputs)\n",
    "    conv1 = Conv2D(16, 3, activation='relu', padding='same')(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "\n",
    "    conv2 = Conv2D(32, 3, activation='relu', padding='same')(pool1)\n",
    "    conv2 = Conv2D(32, 3, activation='relu', padding='same')(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "\n",
    "    conv3 = Conv2D(64, 3, activation='relu', padding='same')(pool2)\n",
    "    conv3 = Conv2D(64, 3, activation='relu', padding='same')(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "\n",
    "    conv4 = Conv2D(128, 3, activation='relu', padding='same')(pool3)\n",
    "    conv4 = Conv2D(128, 3, activation='relu', padding='same')(conv4)\n",
    "    drop4 = Dropout(0.5)(conv4)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n",
    "\n",
    "    conv5 = Conv2D(256, 3, activation='relu', padding='same')(pool4)\n",
    "    conv5 = Conv2D(256, 3, activation='relu', padding='same')(conv5)\n",
    "    drop5 = Dropout(0.5)(conv5)\n",
    "\n",
    "    up6 = Conv2DTranspose(128, 2, strides=(2, 2), padding='same')(drop5)\n",
    "    up6 = concatenate([up6, conv4])\n",
    "    conv6 = Conv2D(128, 3, activation='relu', padding='same')(up6)\n",
    "    conv6 = Conv2D(128, 3, activation='relu', padding='same')(conv6)\n",
    "\n",
    "    up7 = Conv2DTranspose(64, 2, strides=(2, 2), padding='same')(conv6)\n",
    "    up7 = concatenate([up7, conv3])\n",
    "    conv7 = Conv2D(64, 3, activation='relu', padding='same')(up7)\n",
    "    conv7 = Conv2D(64, 3, activation='relu', padding='same')(conv7)\n",
    "\n",
    "    up8 = Conv2DTranspose(32, 2, strides=(2, 2), padding='same')(conv7)\n",
    "    up8 = concatenate([up8, conv2])\n",
    "    conv8 = Conv2D(32, 3, activation='relu', padding='same')(up8)\n",
    "    conv8 = Conv2D(32, 3, activation='relu', padding='same')(conv8)\n",
    "\n",
    "    up9 = Conv2DTranspose(16, 2, strides=(2, 2), padding='same')(conv8)\n",
    "    up9 = concatenate([up9, conv1], axis=3)\n",
    "    conv9 = Conv2D(16, 3, activation='relu', padding='same')(up9)\n",
    "    conv9 = Conv2D(16, 3, activation='relu', padding='same')(conv9)\n",
    "\n",
    "    outputs = Conv2D(1, 1, activation='sigmoid')(conv9)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "    # conv1 = Conv2D(64, 3, activation='relu', padding='same')(inputs)\n",
    "    # conv1 = Conv2D(64, 3, activation='relu', padding='same')(conv1)\n",
    "    # pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "\n",
    "    # conv2 = Conv2D(128, 3, activation='relu', padding='same')(pool1)\n",
    "    # conv2 = Conv2D(128, 3, activation='relu', padding='same')(conv2)\n",
    "    # pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "\n",
    "    # conv3 = Conv2D(256, 3, activation='relu', padding='same')(pool2)\n",
    "    # conv3 = Conv2D(256, 3, activation='relu', padding='same')(conv3)\n",
    "    # pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "\n",
    "    # conv4 = Conv2D(512, 3, activation='relu', padding='same')(pool3)\n",
    "    # conv4 = Conv2D(512, 3, activation='relu', padding='same')(conv4)\n",
    "    # drop4 = Dropout(0.5)(conv4)\n",
    "    # pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n",
    "\n",
    "    # # 디코더 부분\n",
    "    # conv5 = Conv2D(1024, 3, activation='relu', padding='same')(pool4)\n",
    "    # conv5 = Conv2D(1024, 3, activation='relu', padding='same')(conv5)\n",
    "    # drop5 = Dropout(0.5)(conv5)\n",
    "\n",
    "    # up6 = Conv2DTranspose(512, 2, strides=(2, 2), padding='same')(drop5)\n",
    "    # up6 = concatenate([up6, drop4])\n",
    "    # conv6 = Conv2D(512, 3, activation='relu', padding='same')(up6)\n",
    "    # conv6 = Conv2D(512, 3, activation='relu', padding='same')(conv6)\n",
    "\n",
    "    # up7 = Conv2DTranspose(256, 2, strides=(2, 2), padding='same')(conv6)\n",
    "    # up7 = concatenate([up7, conv3])\n",
    "    # conv7 = Conv2D(256, 3, activation='relu', padding='same')(up7)\n",
    "    # conv7 = Conv2D(256, 3, activation='relu', padding='same')(conv7)\n",
    "\n",
    "    # up8 = Conv2DTranspose(128, 2, strides=(2, 2), padding='same')(conv7)\n",
    "    # up8 = concatenate([up8, conv2])\n",
    "    # conv8 = Conv2D(128, 3, activation='relu', padding='same')(up8)\n",
    "    # conv8 = Conv2D(128, 3, activation='relu', padding='same')(conv8)\n",
    "\n",
    "    # up9 = Conv2DTranspose(64, 2, strides=(2, 2), padding='same')(conv8)\n",
    "    # up9 = concatenate([up9, conv1], axis=3)\n",
    "    # conv9 = Conv2D(64, 3, activation='relu', padding='same')(up9)\n",
    "    # conv9 = Conv2D(64, 3, activation='relu', padding='same')(conv9)\n",
    "\n",
    "    # outputs = Conv2D(1, 1, activation='sigmoid')(conv9)\n",
    "\n",
    "    # model = Model(inputs=inputs, outputs=outputs)\n",
    "    # return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU\n"
     ]
    }
   ],
   "source": [
    "gpu_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpu_devices:\n",
    "    print('Using GPU')\n",
    "    # limit GPU Virtual Memory for 5GB\n",
    "    tf.config.experimental.set_virtual_device_configuration(gpu_devices[0],\n",
    "        [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=512)])\n",
    "    # tf.config.experimental.set_memory_growth(gpu_devices[0], True) # can't use when set_virtual_device\n",
    "else:\n",
    "    print('Using CPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 입력 이미지의 크기 지정\n",
    "input_shape = (224, 224, 3)\n",
    "\n",
    "# U-Net 모델 생성\n",
    "model = unet(input_shape)\n",
    "\n",
    "# 모델 컴파일 설정\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "\n",
    "# 데이터셋 경로 설정 \n",
    "train_images_dir = \"C:\\\\open\\\\open\\\\224_train_sample\"\n",
    "train_masks_dir = \"C:\\\\open\\\\open\\\\224_mask_sample\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ImageDataGenerator를 사용하여 train 이미지와 mask 이미지를 불러옴\n",
    "image_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
    "mask_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 25 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "# train 이미지와 mask 이미지를 불러와서 배치 단위로 제공\n",
    "image_generator = image_datagen.flow_from_directory(\n",
    "    train_images_dir,\n",
    "    target_size=input_shape[:2],\n",
    "    class_mode=None,\n",
    "    batch_size=32,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "mask_generator = mask_datagen.flow_from_directory(\n",
    "    train_masks_dir,\n",
    "    target_size=input_shape[:2],\n",
    "    class_mode=None,\n",
    "    batch_size=32,\n",
    "    seed=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def visualize_images(image_batch, mask_batch, num_images=5):\n",
    "    fig, axes = plt.subplots(num_images, 2, figsize=(8, 12))\n",
    "    axes = axes.ravel()\n",
    "\n",
    "    for i in range(num_images):\n",
    "        axes[i*2].imshow(image_batch[i])\n",
    "        axes[i*2].set_title('Image')\n",
    "        axes[i*2].axis('off')\n",
    "\n",
    "        axes[i*2+1].imshow(mask_batch[i])\n",
    "        axes[i*2+1].set_title('Mask')\n",
    "        axes[i*2+1].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# 이미지 배치와 마스크 배치를 시각화\n",
    "batch_size = 5\n",
    "image_batch, mask_batch = next(train_dataset)\n",
    "visualize_images(image_batch, mask_batch, num_images=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "ename": "NotFoundError",
     "evalue": "Graph execution error:\n\nDetected at node 'model/conv2d_10/Relu' defined at (most recent call last):\n    File \"c:\\Users\\dusrb\\AppData\\Local\\Programs\\Python\\Python37\\lib\\runpy.py\", line 193, in _run_module_as_main\n      \"__main__\", mod_spec)\n    File \"c:\\Users\\dusrb\\AppData\\Local\\Programs\\Python\\Python37\\lib\\runpy.py\", line 85, in _run_code\n      exec(code, run_globals)\n    File \"C:\\Users\\dusrb\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"C:\\Users\\dusrb\\AppData\\Roaming\\Python\\Python37\\site-packages\\traitlets\\config\\application.py\", line 1043, in launch_instance\n      app.start()\n    File \"C:\\Users\\dusrb\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel\\kernelapp.py\", line 712, in start\n      self.io_loop.start()\n    File \"C:\\Users\\dusrb\\AppData\\Roaming\\Python\\Python37\\site-packages\\tornado\\platform\\asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"c:\\Users\\dusrb\\AppData\\Local\\Programs\\Python\\Python37\\lib\\asyncio\\base_events.py\", line 541, in run_forever\n      self._run_once()\n    File \"c:\\Users\\dusrb\\AppData\\Local\\Programs\\Python\\Python37\\lib\\asyncio\\base_events.py\", line 1786, in _run_once\n      handle._run()\n    File \"c:\\Users\\dusrb\\AppData\\Local\\Programs\\Python\\Python37\\lib\\asyncio\\events.py\", line 88, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\Users\\dusrb\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel\\kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"C:\\Users\\dusrb\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel\\kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"C:\\Users\\dusrb\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel\\kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"C:\\Users\\dusrb\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel\\kernelbase.py\", line 730, in execute_request\n      reply_content = await reply_content\n    File \"C:\\Users\\dusrb\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel\\ipkernel.py\", line 387, in do_execute\n      cell_id=cell_id,\n    File \"C:\\Users\\dusrb\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel\\zmqshell.py\", line 528, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"C:\\Users\\dusrb\\AppData\\Roaming\\Python\\Python37\\site-packages\\IPython\\core\\interactiveshell.py\", line 2976, in run_cell\n      raw_cell, store_history, silent, shell_futures, cell_id\n    File \"C:\\Users\\dusrb\\AppData\\Roaming\\Python\\Python37\\site-packages\\IPython\\core\\interactiveshell.py\", line 3030, in _run_cell\n      return runner(coro)\n    File \"C:\\Users\\dusrb\\AppData\\Roaming\\Python\\Python37\\site-packages\\IPython\\core\\async_helpers.py\", line 78, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\Users\\dusrb\\AppData\\Roaming\\Python\\Python37\\site-packages\\IPython\\core\\interactiveshell.py\", line 3258, in run_cell_async\n      interactivity=interactivity, compiler=compiler, result=result)\n    File \"C:\\Users\\dusrb\\AppData\\Roaming\\Python\\Python37\\site-packages\\IPython\\core\\interactiveshell.py\", line 3473, in run_ast_nodes\n      if (await self.run_code(code, result,  async_=asy)):\n    File \"C:\\Users\\dusrb\\AppData\\Roaming\\Python\\Python37\\site-packages\\IPython\\core\\interactiveshell.py\", line 3553, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\dusrb\\AppData\\Local\\Temp\\ipykernel_13096\\3790473839.py\", line 5, in <module>\n      model.fit(train_dataset, epochs=3)\n    File \"c:\\Users\\dusrb\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\", line 1187, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"c:\\Users\\dusrb\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\", line 857, in train_function\n      return step_function(self, iterator)\n    File \"c:\\Users\\dusrb\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\", line 847, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\dusrb\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\", line 840, in run_step\n      outputs = model.train_step(data)\n    File \"c:\\Users\\dusrb\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\", line 797, in train_step\n      y_pred = self(x, training=True)\n    File \"c:\\Users\\dusrb\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\", line 1044, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\dusrb\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\functional.py\", line 420, in call\n      inputs, training=training, mask=mask)\n    File \"c:\\Users\\dusrb\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\functional.py\", line 555, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"c:\\Users\\dusrb\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\", line 1044, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\dusrb\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\convolutional.py\", line 280, in call\n      return self.activation(outputs)\n    File \"c:\\Users\\dusrb\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\keras\\activations.py\", line 312, in relu\n      return backend.relu(x, alpha=alpha, max_value=max_value, threshold=threshold)\n    File \"c:\\Users\\dusrb\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\", line 4747, in relu\n      x = nn.relu(x)\nNode: 'model/conv2d_10/Relu'\nNo algorithm worked!  Error messages:\n  Profiling failure on CUDNN engine 1#TC: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 17962624 bytes.\n  Profiling failure on CUDNN engine 1: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 17962624 bytes.\n  Profiling failure on CUDNN engine 0#TC: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 16777216 bytes.\n  Profiling failure on CUDNN engine 0: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 16777216 bytes.\n  Profiling failure on CUDNN engine 2#TC: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 197410816 bytes.\n  Profiling failure on CUDNN engine 2: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 197410816 bytes.\n  Profiling failure on CUDNN engine 4#TC: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 358875136 bytes.\n  Profiling failure on CUDNN engine 4: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 358875136 bytes.\n  Profiling failure on CUDNN engine 6#TC: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 20055552 bytes.\n  Profiling failure on CUDNN engine 6: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 20055552 bytes.\n  Profiling failure on CUDNN engine 5#TC: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 201162752 bytes.\n  Profiling failure on CUDNN engine 5: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 201162752 bytes.\n  Profiling failure on CUDNN engine 7#TC: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 108199936 bytes.\n  Profiling failure on CUDNN engine 7: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 108199936 bytes.\n\t [[{{node model/conv2d_10/Relu}}]] [Op:__inference_train_function_2624]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_13096\\3790473839.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# 모델 학습\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# 학습된 모델 저장\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\dusrb\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1185\u001b[0m                 _r=1):\n\u001b[0;32m   1186\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1187\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1188\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1189\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\dusrb\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 153\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    154\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    155\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\dusrb\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 55\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     56\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNotFoundError\u001b[0m: Graph execution error:\n\nDetected at node 'model/conv2d_10/Relu' defined at (most recent call last):\n    File \"c:\\Users\\dusrb\\AppData\\Local\\Programs\\Python\\Python37\\lib\\runpy.py\", line 193, in _run_module_as_main\n      \"__main__\", mod_spec)\n    File \"c:\\Users\\dusrb\\AppData\\Local\\Programs\\Python\\Python37\\lib\\runpy.py\", line 85, in _run_code\n      exec(code, run_globals)\n    File \"C:\\Users\\dusrb\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"C:\\Users\\dusrb\\AppData\\Roaming\\Python\\Python37\\site-packages\\traitlets\\config\\application.py\", line 1043, in launch_instance\n      app.start()\n    File \"C:\\Users\\dusrb\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel\\kernelapp.py\", line 712, in start\n      self.io_loop.start()\n    File \"C:\\Users\\dusrb\\AppData\\Roaming\\Python\\Python37\\site-packages\\tornado\\platform\\asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"c:\\Users\\dusrb\\AppData\\Local\\Programs\\Python\\Python37\\lib\\asyncio\\base_events.py\", line 541, in run_forever\n      self._run_once()\n    File \"c:\\Users\\dusrb\\AppData\\Local\\Programs\\Python\\Python37\\lib\\asyncio\\base_events.py\", line 1786, in _run_once\n      handle._run()\n    File \"c:\\Users\\dusrb\\AppData\\Local\\Programs\\Python\\Python37\\lib\\asyncio\\events.py\", line 88, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\Users\\dusrb\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel\\kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"C:\\Users\\dusrb\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel\\kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"C:\\Users\\dusrb\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel\\kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"C:\\Users\\dusrb\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel\\kernelbase.py\", line 730, in execute_request\n      reply_content = await reply_content\n    File \"C:\\Users\\dusrb\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel\\ipkernel.py\", line 387, in do_execute\n      cell_id=cell_id,\n    File \"C:\\Users\\dusrb\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel\\zmqshell.py\", line 528, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"C:\\Users\\dusrb\\AppData\\Roaming\\Python\\Python37\\site-packages\\IPython\\core\\interactiveshell.py\", line 2976, in run_cell\n      raw_cell, store_history, silent, shell_futures, cell_id\n    File \"C:\\Users\\dusrb\\AppData\\Roaming\\Python\\Python37\\site-packages\\IPython\\core\\interactiveshell.py\", line 3030, in _run_cell\n      return runner(coro)\n    File \"C:\\Users\\dusrb\\AppData\\Roaming\\Python\\Python37\\site-packages\\IPython\\core\\async_helpers.py\", line 78, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\Users\\dusrb\\AppData\\Roaming\\Python\\Python37\\site-packages\\IPython\\core\\interactiveshell.py\", line 3258, in run_cell_async\n      interactivity=interactivity, compiler=compiler, result=result)\n    File \"C:\\Users\\dusrb\\AppData\\Roaming\\Python\\Python37\\site-packages\\IPython\\core\\interactiveshell.py\", line 3473, in run_ast_nodes\n      if (await self.run_code(code, result,  async_=asy)):\n    File \"C:\\Users\\dusrb\\AppData\\Roaming\\Python\\Python37\\site-packages\\IPython\\core\\interactiveshell.py\", line 3553, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\dusrb\\AppData\\Local\\Temp\\ipykernel_13096\\3790473839.py\", line 5, in <module>\n      model.fit(train_dataset, epochs=3)\n    File \"c:\\Users\\dusrb\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\", line 1187, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"c:\\Users\\dusrb\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\", line 857, in train_function\n      return step_function(self, iterator)\n    File \"c:\\Users\\dusrb\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\", line 847, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\dusrb\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\", line 840, in run_step\n      outputs = model.train_step(data)\n    File \"c:\\Users\\dusrb\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\", line 797, in train_step\n      y_pred = self(x, training=True)\n    File \"c:\\Users\\dusrb\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\", line 1044, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\dusrb\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\functional.py\", line 420, in call\n      inputs, training=training, mask=mask)\n    File \"c:\\Users\\dusrb\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\functional.py\", line 555, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"c:\\Users\\dusrb\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\", line 1044, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\dusrb\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\convolutional.py\", line 280, in call\n      return self.activation(outputs)\n    File \"c:\\Users\\dusrb\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\keras\\activations.py\", line 312, in relu\n      return backend.relu(x, alpha=alpha, max_value=max_value, threshold=threshold)\n    File \"c:\\Users\\dusrb\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\", line 4747, in relu\n      x = nn.relu(x)\nNode: 'model/conv2d_10/Relu'\nNo algorithm worked!  Error messages:\n  Profiling failure on CUDNN engine 1#TC: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 17962624 bytes.\n  Profiling failure on CUDNN engine 1: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 17962624 bytes.\n  Profiling failure on CUDNN engine 0#TC: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 16777216 bytes.\n  Profiling failure on CUDNN engine 0: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 16777216 bytes.\n  Profiling failure on CUDNN engine 2#TC: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 197410816 bytes.\n  Profiling failure on CUDNN engine 2: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 197410816 bytes.\n  Profiling failure on CUDNN engine 4#TC: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 358875136 bytes.\n  Profiling failure on CUDNN engine 4: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 358875136 bytes.\n  Profiling failure on CUDNN engine 6#TC: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 20055552 bytes.\n  Profiling failure on CUDNN engine 6: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 20055552 bytes.\n  Profiling failure on CUDNN engine 5#TC: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 201162752 bytes.\n  Profiling failure on CUDNN engine 5: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 201162752 bytes.\n  Profiling failure on CUDNN engine 7#TC: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 108199936 bytes.\n  Profiling failure on CUDNN engine 7: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 108199936 bytes.\n\t [[{{node model/conv2d_10/Relu}}]] [Op:__inference_train_function_2624]"
     ]
    }
   ],
   "source": [
    "# image_generator와 mask_generator를 결합하여 학습 데이터셋 생성\n",
    "train_dataset = zip(image_generator, mask_generator)\n",
    "\n",
    "# 모델 학습\n",
    "model.fit(train_dataset, epochs=3)\n",
    "\n",
    "# 학습된 모델 저장\n",
    "model.save(\"C:\\\\open\\\\open\\\\U-net_model_sample\\\\model_sample.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
