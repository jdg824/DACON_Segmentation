{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cv2'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_940\\1856958152.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mModel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mInput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mConv2D\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mMaxPooling2D\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mUpSampling2D\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconcatenate\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'cv2'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unet_model(input_shape):\n",
    "    inputs = Input(input_shape)\n",
    "\n",
    "    # Encoder\n",
    "    conv1 = Conv2D(64, 3, activation='relu', padding='same')(inputs)\n",
    "    conv1 = Conv2D(64, 3, activation='relu', padding='same')(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "\n",
    "    conv2 = Conv2D(128, 3, activation='relu', padding='same')(pool1)\n",
    "    conv2 = Conv2D(128, 3, activation='relu', padding='same')(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "\n",
    "    conv3 = Conv2D(256, 3, activation='relu', padding='same')(pool2)\n",
    "    conv3 = Conv2D(256, 3, activation='relu', padding='same')(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "\n",
    "    conv4 = Conv2D(512, 3, activation='relu', padding='same')(pool3)\n",
    "    conv4 = Conv2D(512, 3, activation='relu', padding='same')(conv4)\n",
    "    drop4 = Dropout(0.5)(conv4)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n",
    "\n",
    "    conv5 = Conv2D(1024, 3, activation='relu', padding='same')(pool4)\n",
    "    conv5 = Conv2D(1024, 3, activation='relu', padding='same')(conv5)\n",
    "    drop5 = Dropout(0.5)(conv5)\n",
    "\n",
    "    # Decoder\n",
    "    up6 = Conv2D(512, 2, activation='relu', padding='same')(UpSampling2D(size=(2, 2))(drop5))\n",
    "    merge6 = concatenate([drop4, up6], axis=3)\n",
    "    conv6 = Conv2D(512, 3, activation='relu', padding='same')(merge6)\n",
    "    conv6 = Conv2D(512, 3, activation='relu', padding='same')(conv6)\n",
    "\n",
    "    up7 = Conv2D(256, 2, activation='relu', padding='same')(UpSampling2D(size=(2, 2))(conv6))\n",
    "    merge7 = concatenate([conv3, up7], axis=3)\n",
    "    conv7 = Conv2D(256, 3, activation='relu', padding='same')(merge7)\n",
    "    conv7 = Conv2D(256, 3, activation='relu', padding='same')(conv7)\n",
    "\n",
    "    up8 = Conv2D(128, 2, activation='relu', padding='same')(UpSampling2D(size=(2, 2))(conv7))\n",
    "    merge8 = concatenate([conv2, up8], axis=3)\n",
    "    conv8 = Conv2D(128, 3, activation='relu', padding='same')(merge8)\n",
    "    conv8 = Conv2D(128, 3, activation='relu', padding='same')(conv8)\n",
    "\n",
    "    up9 = Conv2D(64, 2, activation='relu', padding='same')(UpSampling2D(size=(2, 2))(conv8))\n",
    "    merge9 = concatenate([conv1, up9], axis=3)\n",
    "    conv9 = Conv2D(64, 3, activation='relu', padding='same')(merge9)\n",
    "    conv9 = Conv2D(64, 3, activation='relu', padding='same')(conv9)\n",
    "    conv9 = Conv2D(2, 3, activation='relu', padding='same')(conv9)\n",
    "\n",
    "    # Output\n",
    "    outputs = Conv2D(1, 1, activation='sigmoid')(conv9)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    model.compile(optimizer=Adam(learning_rate=1e-4), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "def load_data(image_folder, mask_folder):\n",
    "    image_files = sorted(glob.glob(os.path.join(image_folder, '*.png')))\n",
    "    mask_files = sorted(glob.glob(os.path.join(mask_folder, '*.png')))\n",
    "    images = []\n",
    "    masks = []\n",
    "\n",
    "    for img_file, mask_file in zip(image_files, mask_files):\n",
    "        image = cv2.imread(img_file, cv2.IMREAD_UNCHANGED)\n",
    "        mask = cv2.imread(mask_file, cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "        if image is None or mask is None:\n",
    "            print(f\"Failed to load image or mask: {img_file}, {mask_file}\")\n",
    "            continue\n",
    "\n",
    "        if image.shape[:2] != mask.shape[:2]:\n",
    "            print(f\"Image and mask sizes do not match: {img_file}, {mask_file}\")\n",
    "            continue\n",
    "\n",
    "        images.append(image)\n",
    "        masks.append(mask)\n",
    "\n",
    "    masks = np.array(masks) / 255.0\n",
    "    images = np.array(images)\n",
    "\n",
    "    return images, masks\n",
    "\n",
    "\n",
    "# def load_data(image_folder, mask_folder, crop_size):\n",
    "#     image_files = sorted(os.listdir(image_folder))\n",
    "#     mask_files = sorted(os.listdir(mask_folder))\n",
    "#     images = []\n",
    "#     masks = []\n",
    "\n",
    "#     for img_file, mask_file in zip(image_files, mask_files):\n",
    "#         img_path = os.path.join(image_folder, img_file)\n",
    "#         mask_path = os.path.join(mask_folder, mask_file)\n",
    "\n",
    "#         # Load images and masks\n",
    "#         image = cv2.imread(img_path)\n",
    "#         mask = cv2.imread(mask_path, 0)\n",
    "\n",
    "#         if image is None or mask is None:\n",
    "#             print(f\"Failed to load image or mask: {img_file}, {mask_file}\")\n",
    "#             continue\n",
    "\n",
    "#         # Check if image and mask sizes match\n",
    "#         if image.shape[:2] != mask.shape[:2]:\n",
    "#             print(f\"Image and mask sizes do not match: {img_file}, {mask_file}\")\n",
    "#             continue\n",
    "\n",
    "#         # Crop image and mask\n",
    "#         cropped_images = []\n",
    "#         cropped_masks = []\n",
    "#         h, w = image.shape[:2]\n",
    "#         for i in range(0, h - crop_size + 1, crop_size):\n",
    "#             for j in range(0, w - crop_size + 1, crop_size):\n",
    "#                 cropped_image = image[i:i+crop_size, j:j+crop_size]\n",
    "#                 cropped_mask = mask[i:i+crop_size, j:j+crop_size]\n",
    "#                 cropped_images.append(cropped_image)\n",
    "#                 cropped_masks.append(cropped_mask)\n",
    "\n",
    "#         images.extend(cropped_images)\n",
    "#         masks.extend(cropped_masks)\n",
    "\n",
    "#     images = np.array(images)\n",
    "#     masks = np.array(masks) / 255.0  # Normalize masks to values between 0 and 1\n",
    "\n",
    "#     return images, masks\n",
    "\n",
    "# 병렬 처리를 통해 이미지를 더 빨리 부르기 해\n",
    "\n",
    "# import multiprocessing\n",
    "# from functools import partial\n",
    "\n",
    "# def load_image(image_folder, img_file):\n",
    "#     img_path = os.path.join(image_folder, img_file)\n",
    "#     image = cv2.imread(img_path)\n",
    "#     return image\n",
    "\n",
    "# def load_mask(mask_folder, mask_file):\n",
    "#     mask_path = os.path.join(mask_folder, mask_file)\n",
    "#     mask = cv2.imread(mask_path, 0)\n",
    "#     return mask\n",
    "\n",
    "# def load_data(image_folder, mask_folder, crop_size):\n",
    "#     image_files = sorted(os.listdir(image_folder))\n",
    "#     mask_files = sorted(os.listdir(mask_folder))\n",
    "\n",
    "#     with multiprocessing.Pool() as pool:\n",
    "#         images = pool.starmap(partial(load_image, image_folder), [(image_folder, img_file) for img_file in image_files])\n",
    "#         masks = pool.starmap(partial(load_mask, mask_folder), [(mask_folder, mask_file) for mask_file in mask_files])\n",
    "\n",
    "\n",
    "#     images = [image for image in images if image is not None]\n",
    "#     masks = [mask for mask in masks if mask is not None]\n",
    "\n",
    "#     # Crop image and mask\n",
    "#     cropped_images = []\n",
    "#     cropped_masks = []\n",
    "#     for image, mask in zip(images, masks):\n",
    "#         h, w = image.shape[:2]\n",
    "#         for i in range(0, h - crop_size + 1, crop_size):\n",
    "#             for j in range(0, w - crop_size + 1, crop_size):\n",
    "#                 cropped_image = image[i:i+crop_size, j:j+crop_size]\n",
    "#                 cropped_mask = mask[i:i+crop_size, j:j+crop_size]\n",
    "#                 cropped_images.append(cropped_image)\n",
    "#                 cropped_masks.append(cropped_mask)\n",
    "\n",
    "#     cropped_images = np.array(cropped_images)\n",
    "#     cropped_masks = np.array(cropped_masks) / 255.0  # Normalize masks to values between 0 and 1\n",
    "\n",
    "#     return cropped_images, cropped_masks\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] 지정된 경로를 찾을 수 없습니다: '/content/gdrive/My Drive/version/train_img'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_940\\3809792807.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mtest_image_folder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'/content/gdrive/My Drive/version/test_img'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mtrain_images\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_masks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_image_folder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_mask_folder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcrop_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m224\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[0mtest_images\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_image_folder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_image_folder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcrop_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m224\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_940\\2797959709.py\u001b[0m in \u001b[0;36mload_data\u001b[1;34m(image_folder, mask_folder, crop_size)\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mload_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_folder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask_folder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcrop_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m     \u001b[0mimage_files\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_folder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m     \u001b[0mmask_files\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmask_folder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m     \u001b[0mimages\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] 지정된 경로를 찾을 수 없습니다: '/content/gdrive/My Drive/version/train_img'"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# 데이터 로드\n",
    "train_image_folder = \"C:\\\\Users\\\\IT\\\\Desktop\\\\ai\\\\train_img\"\n",
    "train_mask_folder = \"C:\\\\Users\\\\IT\\\\Desktop\\\\ai\\\\train_mask\"\n",
    "test_image_folder = \"C:\\\\Users\\\\IT\\\\Desktop\\\\ai\\\\test_img\"\n",
    "\n",
    "train_images, train_masks = load_data(train_image_folder, train_mask_folder, crop_size=224)\n",
    "test_images, _ = load_data(test_image_folder, test_image_folder, crop_size=224)\n",
    "\n",
    "# 타깃 데이터를 원-핫 인코딩\n",
    "train_masks = to_categorical(train_masks, num_classes=2)\n",
    "\n",
    "# U-Net 모델 생성\n",
    "input_shape = (224, 224, 3)  # Updated input shape to match resized train images and masks\n",
    "model = unet_model(input_shape)\n",
    "\n",
    "# 모델 학습\n",
    "model.fit(train_images, train_masks, batch_size=3, epochs=2)  # Removed reshape step\n",
    "\n",
    "# 모델 저장\n",
    "model.save(\"./train_model\")\n",
    "\n",
    "# # 테스트 데이터 예측\n",
    "# resized_test_images = []\n",
    "# for image in test_images:\n",
    "#     resized_image = cv2.resize(image, (224, 224))\n",
    "#     resized_test_images.append(resized_image)\n",
    "# resized_test_images = np.array(resized_test_images)\n",
    "\n",
    "# predictions = model.predict(resized_test_images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import numpy as np\n",
    "# import cv2\n",
    "# from tensorflow.keras.models import load_model\n",
    "# from google.colab.patches import cv2_imshow\n",
    "\n",
    "# # 학습된 모델 불러오기\n",
    "# model = load_model(\"./train_model\")\n",
    "\n",
    "# # 테스트 이미지 폴더 경로\n",
    "# test_image_folder = '/content/gdrive/My Drive/version/test_img'\n",
    "\n",
    "# # 결과 이미지 저장 폴더 경로\n",
    "# output_folder = '/content/gdrive/My Drive/version/output'\n",
    "\n",
    "# # 결과 이미지 저장 폴더가 없다면 생성\n",
    "# os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# # 테스트 이미지 파일 목록\n",
    "# test_image_files = sorted(os.listdir(test_image_folder))\n",
    "\n",
    "# # 테스트 이미지 예측 및 저장\n",
    "# for img_file in test_image_files:\n",
    "#     img_path = os.path.join(test_image_folder, img_file)\n",
    "\n",
    "#     # 테스트 이미지 로드 및 크기 조정\n",
    "#     image = cv2.imread(img_path)\n",
    "#     resized_image = cv2.resize(image, (1024, 1024))\n",
    "\n",
    "#     # 예측\n",
    "#     prediction = model.predict(np.expand_dims(resized_image, axis=0))[0]\n",
    "#     pred_mask = (prediction > 0.5).astype(np.uint8) * 255\n",
    "\n",
    "#     # 예측 이미지 크기 조정\n",
    "#     resized_pred_mask = cv2.resize(pred_mask, (224, 224))\n",
    "\n",
    "#     # 결과 이미지 저장\n",
    "#     output_path = os.path.join(output_folder, f\"prediction_{img_file}\")\n",
    "#     cv2.imwrite(output_path, resized_pred_mask)\n",
    "\n",
    "#     # 시각화 (일부 이미지만)\n",
    "#     cv2_imshow(pred_mask)\n",
    "#     cv2.waitKey(0)\n",
    "\n",
    "# cv2.destroyAllWindows()\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from tensorflow.keras.models import load_model\n",
    "from google.colab.patches import cv2_imshow\n",
    "\n",
    "# 학습된 모델 불러오기\n",
    "model = load_model(\"./train_model\")\n",
    "\n",
    "# 테스트 이미지 폴더 경로\n",
    "test_image_folder = '/content/gdrive/My Drive/version/test_img'\n",
    "\n",
    "# 결과 이미지 저장 폴더 경로\n",
    "output_folder = '/content/gdrive/My Drive/version/output5'\n",
    "\n",
    "# 결과 이미지 저장 폴더가 없다면 생성\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# 테스트 이미지 파일 목록\n",
    "test_image_files = sorted(os.listdir(test_image_folder))\n",
    "\n",
    "# 테스트 이미지 예측 및 저장\n",
    "for img_file in test_image_files:\n",
    "    img_path = os.path.join(test_image_folder, img_file)\n",
    "\n",
    "    # 테스트 이미지 로드 및 크기 조정\n",
    "    image = cv2.imread(img_path)\n",
    "    resized_image = cv2.resize(image, (224, 224))\n",
    "\n",
    "    # 예측\n",
    "    prediction = model.predict(np.expand_dims(resized_image, axis=0))[0]\n",
    "    pred_mask = (prediction > 0.5).astype(np.uint8) * 255\n",
    "\n",
    "    # 결과 이미지 저장\n",
    "    output_path = os.path.join(output_folder, f\"prediction_{img_file}\")\n",
    "    cv2.imwrite(output_path, pred_mask)\n",
    "\n",
    "    # 시각화 (일부 이미지만)\n",
    "    cv2_imshow(pred_mask)\n",
    "    cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
