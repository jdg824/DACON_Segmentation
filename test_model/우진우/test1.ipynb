{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RLE 디코딩 함수\n",
    "def rle_decode(mask_rle, shape):\n",
    "    s = mask_rle.split()\n",
    "    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n",
    "    starts -= 1\n",
    "    ends = starts + lengths\n",
    "    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n",
    "    for lo, hi in zip(starts, ends):\n",
    "        img[lo:hi] = 1\n",
    "    return img.reshape(shape)\n",
    "\n",
    "# RLE 인코딩 함수\n",
    "def rle_encode(mask):\n",
    "    pixels = mask.flatten()\n",
    "    pixels = np.concatenate([[0], pixels, [0]])\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "    runs[1::2] -= runs[::2]\n",
    "    return ' '.join(str(x) for x in runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'albumentations'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_7480\\3145360516.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0malbumentations\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mA\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mSatelliteDataset\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'albumentations'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import numpy as np\n",
    "import albumentations as A\n",
    "\n",
    "class SatelliteDataset:\n",
    "    def __init__(self, csv_file, transform=None, infer=False):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.transform = transform\n",
    "        self.infer = infer\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.data.iloc[idx, 1]\n",
    "        image = cv2.imread(img_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        if self.infer:\n",
    "            if self.transform:\n",
    "                image = self.transform(image)\n",
    "            return image\n",
    "\n",
    "        mask_rle = self.data.iloc[idx, 2]\n",
    "        mask = rle_decode(mask_rle, (image.shape[0], image.shape[1]))\n",
    "\n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=image, mask=mask)\n",
    "            image = augmented['image']\n",
    "            mask = augmented['mask']\n",
    "\n",
    "        return image, mask\n",
    "\n",
    "def preprocess(image, mask):\n",
    "    # Preprocessing steps for image and mask (if needed)\n",
    "    image = image / 255.0  # Normalize image\n",
    "    mask = mask / 255.0  # Normalize mask\n",
    "    return image, mask\n",
    "\n",
    "def load_and_preprocess_img(img_path, mask_rle):\n",
    "    image = tf.io.read_file(img_path)\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    mask = rle_decode(mask_rle, (image.shape[0], image.shape[1]))\n",
    "    image, mask = preprocess(image, mask)\n",
    "    return image, mask\n",
    "\n",
    "transform = A.Compose(\n",
    "    [\n",
    "        A.Resize(224, 224),\n",
    "        A.Normalize(),\n",
    "    ]\n",
    ")\n",
    "\n",
    "def apply_transform(image, mask):\n",
    "    augmented = transform(image=image.numpy(), mask=mask.numpy())\n",
    "    return augmented['image'], augmented['mask']\n",
    "\n",
    "dataset = SatelliteDataset(csv_file='/content/gdrive/MyDrive/train.csv', transform=apply_transform)\n",
    "\n",
    "dataset = tf.data.Dataset.from_generator(\n",
    "    lambda: dataset,\n",
    "    output_signature=(\n",
    "        tf.TensorSpec(shape=(None, None, 3), dtype=tf.float32),\n",
    "        tf.TensorSpec(shape=(None, None), dtype=tf.float32)\n",
    "    )\n",
    ")\n",
    "\n",
    "dataloader = dataset.map(load_and_preprocess_img, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "dataloader = dataset.batch(16)\n",
    "dataloader = dataset.shuffle(buffer_size=1000)\n",
    "dataloader = dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Double Convolution Block 정의\n",
    "def double_conv(in_channels, out_channels):\n",
    "    return tf.keras.Sequential([\n",
    "        layers.Conv2D(out_channels, 3, padding='same'),\n",
    "        layers.ReLU(),\n",
    "        layers.Conv2D(out_channels, 3, padding='same'),\n",
    "        layers.ReLU()\n",
    "    ])\n",
    "\n",
    "# 간단한 U-Net 모델 정의\n",
    "class UNet(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(UNet, self).__init__()\n",
    "        self.dconv_down1 = double_conv(3, 64)\n",
    "        self.dconv_down2 = double_conv(64, 128)\n",
    "        self.dconv_down3 = double_conv(128, 256)\n",
    "        self.dconv_down4 = double_conv(256, 512)\n",
    "\n",
    "        self.maxpool = layers.MaxPooling2D(2)\n",
    "        self.upsample = layers.UpSampling2D(size=(2, 2), interpolation='bilinear')\n",
    "\n",
    "        self.dconv_up3 = double_conv(256 + 512, 256)\n",
    "        self.dconv_up2 = double_conv(128 + 256, 128)\n",
    "        self.dconv_up1 = double_conv(128 + 64, 64)\n",
    "\n",
    "        self.conv_last = layers.Conv2D(1, 1)\n",
    "\n",
    "    def call(self, x):\n",
    "        conv1 = self.dconv_down1(x)\n",
    "        x = self.maxpool(conv1)\n",
    "\n",
    "        conv2 = self.dconv_down2(x)\n",
    "        x = self.maxpool(conv2)\n",
    "\n",
    "        conv3 = self.dconv_down3(x)\n",
    "        x = self.maxpool(conv3)\n",
    "\n",
    "        x = self.dconv_down4(x)\n",
    "\n",
    "        x = self.upsample(x)\n",
    "        x = tf.concat([x, conv3], axis=-1)\n",
    "\n",
    "        x = self.dconv_up3(x)\n",
    "        x = self.upsample(x)\n",
    "        x = tf.concat([x, conv2], axis=-1)\n",
    "\n",
    "        x = self.dconv_up2(x)\n",
    "        x = self.upsample(x)\n",
    "        x = tf.concat([x, conv1], axis=-1)\n",
    "\n",
    "        x = self.dconv_up1(x)\n",
    "\n",
    "        out = self.conv_last(x)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model 초기화\n",
    "model = UNet()\n",
    "\n",
    "# loss function 정의\n",
    "loss_object = tf.keras.losses.BinaryCrossentropy()\n",
    "\n",
    "# optimizer 정의\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "@tf.function\n",
    "def train_step(images, masks):\n",
    "    with tf.GradientTape() as tape:\n",
    "        outputs = model(images, training=True)\n",
    "        loss = loss_object(masks, outputs)\n",
    "\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "    return loss\n",
    "\n",
    "# training loop\n",
    "for epoch in range(10):  # 10 에폭 동안 학습합니다.\n",
    "    epoch_loss = 0\n",
    "    for images, masks in tqdm(dataloader):\n",
    "        images = tf.cast(images, tf.float32)\n",
    "        masks = tf.cast(masks, tf.float32)\n",
    "\n",
    "        loss = train_step(images, masks)\n",
    "        epoch_loss += loss\n",
    "\n",
    "    print(f'Epoch {epoch+1}, Loss: {epoch_loss/len(dataloader)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
